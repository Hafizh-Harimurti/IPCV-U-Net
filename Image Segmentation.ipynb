{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentasi Citra *Cable Icing* Menggunakan U-Net"
      ],
      "metadata": {
        "id": "TauCxYEpPBq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Persiapan model dan fungsi yang akan digunakan"
      ],
      "metadata": {
        "id": "RghidfKdPRTn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmWJrgeEEBZq"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import Input, Model, Sequential\n",
        "from keras.layers import BatchNormalization, Concatenate, Conv2D, Conv2DTranspose, Dropout, MaxPooling2D, RandomFlip, RandomTranslation, RandomZoom, ReLU\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.metrics import MeanIoU\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sOFvN83t3-j"
      },
      "outputs": [],
      "source": [
        "# Base directory\n",
        "base = '/content/drive/MyDrive/Tugas IPCV Image Segmentation'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_sizes = np.array([1024, 768])\n",
        "new_image_sizes = np.uint16(image_sizes/4)\n",
        "\n",
        "rng = np.random.default_rng(seed = 10)"
      ],
      "metadata": {
        "id": "z5HpihhLPAQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pembuatan model u-net"
      ],
      "metadata": {
        "id": "eWVxTZisPilA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdS4Ow6jYFfG"
      },
      "outputs": [],
      "source": [
        "def doubleConvolution(features, input):\n",
        "\n",
        "  conv1 = Conv2D(features, (3,3), kernel_initializer = 'he_normal', padding = 'same') (input)\n",
        "  batch_norm1 = BatchNormalization() (conv1)\n",
        "  relu1 = ReLU() (batch_norm1)\n",
        "\n",
        "  conv2 = Conv2D(features, (3,3), kernel_initializer = 'he_normal', padding = 'same') (relu1)\n",
        "  batch_norm2 = BatchNormalization() (conv2)\n",
        "  relu2 = ReLU() (batch_norm2)\n",
        "  return relu2\n",
        "\n",
        "def contractingPath(features, input):\n",
        "  convolution = doubleConvolution(features, input)\n",
        "  pooling = MaxPooling2D((2,2), strides = 2) (convolution)\n",
        "  dropout = Dropout(0.3) (pooling)\n",
        "  return convolution, dropout\n",
        "\n",
        "def expandingPath(features, input, contracting_conv):\n",
        "  deconvolution = Conv2DTranspose(features, (2,2), kernel_initializer = 'he_normal', strides = 2, padding = 'same') (input)\n",
        "  concat = Concatenate() ([contracting_conv, deconvolution])\n",
        "  dropout = Dropout(0.3) (concat)\n",
        "  convolution = doubleConvolution(features, dropout)\n",
        "  return convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ys4dCrQhYUUx"
      },
      "outputs": [],
      "source": [
        "input = Input(shape=(new_image_sizes[1],new_image_sizes[0],3))\n",
        "\n",
        "left_conv1, contract1 = contractingPath(64, input)\n",
        "left_conv2, contract2 = contractingPath(128, contract1)\n",
        "left_conv3, contract3 = contractingPath(256, contract2)\n",
        "left_conv4, contract4 = contractingPath(512, contract3)\n",
        "\n",
        "left_conv5 = doubleConvolution(1024, contract4)\n",
        "contract5 = Dropout(0.3) (left_conv5)\n",
        "\n",
        "expand1 = expandingPath(512, contract5, left_conv4)\n",
        "expand2 = expandingPath(256, expand1, left_conv3)\n",
        "expand3 = expandingPath(128, expand2, left_conv2)\n",
        "expand4 = expandingPath(64, expand3, left_conv1)\n",
        "\n",
        "output = Conv2D(3, (1,1), kernel_initializer = 'he_normal', padding = 'same') (expand4)\n",
        "\n",
        "u_net_model = Model(input, output)\n",
        "u_net_model.compile(optimizer='SGD', loss=SparseCategoricalCrossentropy(from_logits = True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fungsi untuk peningkatan citra"
      ],
      "metadata": {
        "id": "us3iH_ZjPoW9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnrToILmDgB7"
      },
      "outputs": [],
      "source": [
        "def convertBGR2HSI(imgs):\n",
        "  blue = imgs[:,:,:,0]\n",
        "  green = imgs[:,:,:,1]\n",
        "  red = imgs[:,:,:,2]\n",
        "\n",
        "  denominator = np.square(red-green)+((red-blue)*(green-blue))\n",
        "  modified_denominator = np.where(denominator == 0, 10**-10, denominator)\n",
        "\n",
        "  hue = np.where(denominator > 0, np.arccos(np.clip(0.5*((red-green)+(red-blue))/np.sqrt(modified_denominator), -1, 1)), 0)\n",
        "  hue[blue>green] = 2*np.pi - hue[blue>green]\n",
        "  intensity = (red+green+blue)/3\n",
        "  modified_intensity = np.where(intensity == 0, 10**-10, intensity)\n",
        "  saturation = np.where(intensity == 0, 0, 1 - np.minimum(np.minimum(red, green),blue)/modified_intensity)\n",
        "  return np.stack([np.degrees(hue), saturation, intensity], axis = -1)\n",
        "\n",
        "def convertHSI2BGR(imgs):\n",
        "  hue = imgs[:,:,:,0]\n",
        "  saturation = imgs[:,:,:,1]\n",
        "  intensity = imgs[:,:,:,2]\n",
        "\n",
        "  hue[hue == 0] = 360\n",
        "  hue = np.radians(hue)\n",
        "\n",
        "  blue = np.zeros_like(hue)\n",
        "  green = np.zeros_like(hue)\n",
        "  red = np.zeros_like(hue)\n",
        "\n",
        "  blue = blue + np.where((hue>0)&(hue<=2/3*np.pi),intensity*(1-saturation),0)\n",
        "  red = red + np.where((hue>0)&(hue<=2/3*np.pi),intensity*(1+(saturation*np.cos(hue))/np.cos(np.pi/3-hue)),0)\n",
        "  green = green + np.where((hue>0)&(hue<=2/3*np.pi),3*intensity-(red+blue),0)\n",
        "\n",
        "  red = red + np.where((hue>2/3*np.pi)&(hue<=4/3*np.pi),intensity*(1-saturation),0)\n",
        "  green = green + np.where((hue>2/3*np.pi)&(hue<=4/3*np.pi),intensity*(1+(saturation*np.cos(hue-2/3*np.pi))/np.cos(np.pi-hue)),0)\n",
        "  blue = blue + np.where((hue>2/3*np.pi)&(hue<=4/3*np.pi),3*intensity-(red+green),0)\n",
        "\n",
        "  green = green + np.where((hue>4/3*np.pi)&(hue<=2*np.pi),intensity*(1-saturation),0)\n",
        "  blue = blue + np.where((hue>4/3*np.pi)&(hue<=2*np.pi),intensity*(1+(saturation*np.cos(hue-4/3*np.pi))/np.cos(5/3*np.pi-hue)),0)\n",
        "  red = red + np.where((hue>4/3*np.pi)&(hue<=2*np.pi),3*intensity-(green+blue),0)\n",
        "\n",
        "  return np.clip(np.stack([blue,green,red], axis = -1), 0, 1)\n",
        "\n",
        "def singleScaleRetinex(img, sigma):\n",
        "    img = np.float64(img) + 1\n",
        "    retinex = np.log10(img) - np.log10(cv.GaussianBlur(img, (0, 0), sigma))\n",
        "    return retinex\n",
        "\n",
        "def multiScaleRetinex(img, sigma_list, sigma_weight):\n",
        "    img = np.float64(img)\n",
        "    retinex = np.zeros_like(img)\n",
        "    for index, sigma in enumerate(sigma_list):\n",
        "        retinex += sigma_weight[index] * singleScaleRetinex(img, sigma)\n",
        "    return (retinex-np.min(retinex))/(np.max(retinex)-np.min(retinex))\n",
        "\n",
        "def brightenImagesHE(imgs):\n",
        "  hsi_imgs = convertBGR2HSI(imgs)\n",
        "  intensities = []\n",
        "  for img in hsi_imgs:\n",
        "    intensities.append(cv.equalizeHist((img[:,:,2]*255).astype(np.uint8))/255)\n",
        "  hsi_imgs[:,:,:,2] = np.array(intensities)\n",
        "  bgr_imgs = convertHSI2BGR(hsi_imgs)\n",
        "  return bgr_imgs\n",
        "\n",
        "def brightenImagesMSR(imgs):\n",
        "  sigma_list = [15, 80, 250]\n",
        "  sigma_weight = [1/3, 1/3, 1/3]\n",
        "  brightened_imgs = list()\n",
        "  for img in imgs:\n",
        "    brightened_imgs.append(multiScaleRetinex(img, sigma_list, sigma_weight))\n",
        "  return np.array(brightened_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Persiapan data berisi citra dan *mask*"
      ],
      "metadata": {
        "id": "K4SQ-aTVPyVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation = Sequential(\n",
        "    [RandomFlip('horizontal'),\n",
        "     RandomTranslation(0.2, 0.2),\n",
        "     RandomZoom((-0.2,0.2))]\n",
        ")\n",
        "\n",
        "def createTrainingAndTestSet(combined_imgs, split_amount, augment_amount):\n",
        "  combined_imgs = np.array(combined_imgs)\n",
        "  rng.shuffle(combined_imgs)\n",
        "  combined_train_imgs, combined_test_imgs = [combined_imgs[:np.round(split_amount*combined_imgs.shape[0]).astype(np.uint8)], combined_imgs[np.round(split_amount*combined_imgs.shape[0]).astype(np.uint8):]]\n",
        "\n",
        "  combined_train_imgs = np.repeat(combined_train_imgs, augment_amount, axis = 0)\n",
        "  augmented_combinations = augmentation(tf.convert_to_tensor(combined_train_imgs), training = True).numpy()\n",
        "  augmented_train_imgs = augmented_combinations[:,:,:,:3]\n",
        "  augmented_train_segment_masks = augmented_combinations[:,:,:,3]\n",
        "\n",
        "  test_imgs = combined_test_imgs[:,:,:,:3]\n",
        "  test_segment_masks = combined_test_imgs[:,:,:,3]\n",
        "\n",
        "  return augmented_train_imgs, augmented_train_segment_masks, test_imgs, test_segment_masks"
      ],
      "metadata": {
        "id": "eI27GRsxkUzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCdCyfHnsAZl"
      },
      "outputs": [],
      "source": [
        "combined_img_and_masks_without_normal = []\n",
        "combined_img_and_masks_with_normal = []\n",
        "\n",
        "image_types = [0,0]\n",
        "\n",
        "with os.scandir(base + '/IcingCableLineSegmentation/Segmentations') as it:\n",
        "  for segmentation in it:\n",
        "    current_image_type = 0\n",
        "    json_file = open(segmentation)\n",
        "    converted_file = json.load(json_file)\n",
        "    img_file = cv.resize(cv.imread(base + '/IcingCableLineSegmentation/Images/' + converted_file['imagePath']).astype(np.float32)/255,(new_image_sizes[0], new_image_sizes[1]))\n",
        "    segment_mask = np.zeros((768,1024), dtype = np.uint8)\n",
        "    for mask_shape in converted_file['shapes']:\n",
        "      if mask_shape['label'] == 'line':\n",
        "        current_image_type = 1\n",
        "        cv.fillPoly(segment_mask, [np.int32(np.round(np.array(mask_shape['points']),0))], [1])\n",
        "      elif mask_shape['label'] == 'line_icing':\n",
        "        cv.fillPoly(segment_mask, [np.int32(np.round(np.array(mask_shape['points']),0))], [2])\n",
        "    segment_mask = cv.resize(segment_mask,(new_image_sizes[0], new_image_sizes[1]))\n",
        "    combined_img = np.append(img_file, segment_mask[:,:,None], axis = 2)\n",
        "    if current_image_type == 0:\n",
        "      combined_img_and_masks_without_normal.append(combined_img)\n",
        "    else:\n",
        "      combined_img_and_masks_with_normal.append(combined_img)\n",
        "    image_types[current_image_type] += 1\n",
        "\n",
        "train_imgs_without_normal, train_segment_masks_without_normal, test_imgs_without_normal, test_segment_masks_without_normal = createTrainingAndTestSet(combined_img_and_masks_without_normal, 0.8, 10)\n",
        "train_imgs_with_normal, train_segment_masks_with_normal, test_imgs_with_normal, test_segment_masks_with_normal = createTrainingAndTestSet(combined_img_and_masks_with_normal, 0.8, 21)\n",
        "\n",
        "train_imgs = np.append(train_imgs_without_normal, train_imgs_with_normal, axis = 0)\n",
        "train_segment_masks = np.append(train_segment_masks_without_normal, train_segment_masks_with_normal, axis = 0)\n",
        "test_imgs = np.append(test_imgs_without_normal, test_imgs_with_normal, axis = 0)\n",
        "test_segment_masks = np.append(test_segment_masks_without_normal, test_segment_masks_with_normal, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Images without normal cable:', image_types[0])\n",
        "print('Images with normal cable:', image_types[1])\n",
        "print('Total images:', image_types[0] + image_types[1])"
      ],
      "metadata": {
        "id": "2MRFeyr_hX46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Peningkatan citra *test set*"
      ],
      "metadata": {
        "id": "Suyj7t0sP7gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "he_test_imgs = brightenImagesHE(test_imgs)\n",
        "msr_test_imgs = brightenImagesMSR(test_imgs)"
      ],
      "metadata": {
        "id": "wWnGIe12J-aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pelatihan model u-net"
      ],
      "metadata": {
        "id": "Xo4IPHZfP_03"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfyonjFl1IyN"
      },
      "outputs": [],
      "source": [
        "u_net = u_net_model\n",
        "u_net.fit(train_imgs, train_segment_masks, batch_size = 16)\n",
        "u_net.save(base + '/u_net_model_sparse')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil prediksi menggunakan model yang sudah dilatih"
      ],
      "metadata": {
        "id": "e0e9-h4zQC3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def displayImages(img, true, input_list, pred_list, img_names):\n",
        "  img = (img*255).astype(np.uint8)\n",
        "  colored_preds = list()\n",
        "  for pred in pred_list:\n",
        "    colored_pred = np.full((pred.shape[0],pred.shape[1],3), np.array([0,0,0]), dtype = np.uint8)\n",
        "    colored_pred[pred==1] = np.array([255,0,0])\n",
        "    colored_pred[pred==2] = np.array([0,0,255])\n",
        "    colored_preds.append(colored_pred)\n",
        "  colored_true = np.full((true.shape[0],true.shape[1],3), np.array([0,0,0]), dtype = np.uint8)\n",
        "  colored_true[true==1] = np.array([255,0,0])\n",
        "  colored_true[true==2] = np.array([0,0,255])\n",
        "\n",
        "  cv.imwrite(base+'/Normal Image.png', img)\n",
        "  cv.imwrite(base+'/True Mask.png', cv.cvtColor(colored_true, cv.COLOR_RGB2BGR))\n",
        "  for index in range(len(input_list)):\n",
        "    cv.imwrite(base+'/Input Image {}.png'.format(img_names[index]), np.round(input_list[index]*255).astype(np.uint8))\n",
        "    cv.imwrite(base+'/Predicted Mask {}.png'.format(img_names[index]), cv.cvtColor(colored_preds[index], cv.COLOR_RGB2BGR))\n",
        "    fig = plt.figure(index+1)\n",
        "    fig.suptitle('Result for {}:'.format(img_names[index]), fontsize = 16)\n",
        "    fig.subplots_adjust(top = 1.3)\n",
        "    ax = plt.subplot(141)\n",
        "    plt.imshow(img)\n",
        "    ax.set_title('Original Image')\n",
        "    ax = plt.subplot(142)\n",
        "    plt.imshow(colored_true)\n",
        "    ax.set_title('Ground Truth')\n",
        "    ax = plt.subplot(143)\n",
        "    plt.imshow(input_list[index])\n",
        "    ax.set_title('Input Image')\n",
        "    ax = plt.subplot(144)\n",
        "    plt.imshow(colored_preds[index])\n",
        "    ax.set_title('Mask Prediction')\n",
        "\n",
        "def calculateMeanIoU(true, pred):\n",
        "  mean_iou = MeanIoU(num_classes = 3)\n",
        "  mean_iou.update_state(true, pred)\n",
        "  return mean_iou.result().numpy()"
      ],
      "metadata": {
        "id": "64OzR_OoiFTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_net = load_model(base + '/u_net_model_sparse')"
      ],
      "metadata": {
        "id": "xgVm89Eo4mij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_net_predict_normal = np.argmax(u_net.predict(np.array(test_imgs)),axis = -1)\n",
        "u_net_predict_he = np.argmax(u_net.predict(np.array(he_test_imgs)),axis = -1)\n",
        "u_net_predict_msr = np.argmax(u_net.predict(np.array(msr_test_imgs)),axis = -1)"
      ],
      "metadata": {
        "id": "Q9-wPEUTAX88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tampilan dari hasil peningkatan citra dan prediksi *mask* segmentasi"
      ],
      "metadata": {
        "id": "D1yz8of3QYJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_index = 4\n",
        "\n",
        "all_inputs = [test_imgs[image_index], he_test_imgs[image_index], msr_test_imgs[image_index]]\n",
        "all_predictions = [u_net_predict_normal[image_index], u_net_predict_he[image_index], u_net_predict_msr[image_index]]\n",
        "prediction_names = ['Normal Test Set', 'HE Brightened Test Set', 'MSR Brightened Test Set']\n",
        "\n",
        "displayImages(test_imgs[image_index], test_segment_masks[image_index], all_inputs, all_predictions, prediction_names)"
      ],
      "metadata": {
        "id": "-KrdSVZFBebz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kalkulasi rata-rata IoU setiap prediksi dari citra masukan"
      ],
      "metadata": {
        "id": "Vl9WI_BlQhwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Normal test set MeanIoU: ' + str(calculateMeanIoU(test_segment_masks, u_net_predict_normal)))\n",
        "print('HE brightened test set MeanIoU: ' + str(calculateMeanIoU(test_segment_masks, u_net_predict_he)))\n",
        "print('MSR brightened test set MeanIoU: ' + str(calculateMeanIoU(test_segment_masks, u_net_predict_msr)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZmMIADQCDNA",
        "outputId": "cb2d1801-0499-4f39-bf71-79b87c926473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal test set MeanIoU: 0.58008224\n",
            "HE brightened test set MeanIoU: 0.27235022\n",
            "MSR brightened test set MeanIoU: 0.54899627\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}